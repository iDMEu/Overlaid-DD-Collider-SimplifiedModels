{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8dc43f1-a22e-41df-9b03-44f9a88d3af1",
   "metadata": {},
   "source": [
    "# Overlaying collider and Direct Detection Dark Matter constraints: an example notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125473c1-e6be-4d85-a6c5-0fa3fba301a9",
   "metadata": {},
   "source": [
    "In this notebook, we will overlay different constraints on a vector-mediated dark matter simplified model [1] from future colliders and direct detection experiments.\n",
    "TODO: to be self consistent, we need to include in this cell\n",
    "* Feynman diagram\n",
    "* Sketch of DD\n",
    "* Mention of dijet/monojet\n",
    "* Mention of fixed vs varied couplings\n",
    "* ESCAPE and the Dark Matter Science Project / the Virtual Research Environment\n",
    "* iDMEu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35a6bb-d523-408e-b812-810c6cc66b17",
   "metadata": {},
   "source": [
    "Assorted imports, including a helper script to collect and display direct detection curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b31df7-44e0-4436-8449-550b54ba180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from shapely.geometry import Polygon as shapely_pol\n",
    "import pickle\n",
    "from basic_plotter import *\n",
    "import ROOT\n",
    "import itertools as it\n",
    "import sys, os\n",
    "sys.path.insert(1, '../inputs/directdetection')\n",
    "import collect_dd\n",
    "\n",
    "FULL_SPECTRA_PATH = \"data/Full_spectra\"  # arXiv:[2109.03116]\n",
    "OUTPUT_FOLDER = \"plots\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da71be0",
   "metadata": {},
   "source": [
    "Here we plot the Darkside example plot. WIP Leo: overlaying the HL-LHC plots and future colliders as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Define filenames for the full spectra\n",
    "DS200TY_FULL_SPECTRUM_FILE = \"DarkSide-200ty.txt\"  # DS-20k 200 ton-year projection\n",
    "\n",
    "# Load DarkSide-200ty full spectrum\n",
    "try:\n",
    "    # First try with comma delimiter\n",
    "    try:\n",
    "        ds200ty_mass, ds200ty_xsec = np.loadtxt(os.path.join(FULL_SPECTRA_PATH, DS200TY_FULL_SPECTRUM_FILE), \n",
    "                                          delimiter=',', unpack=True)\n",
    "    except:\n",
    "        # If comma fails, try tab delimiter\n",
    "        ds200ty_mass, ds200ty_xsec = np.loadtxt(os.path.join(FULL_SPECTRA_PATH, DS200TY_FULL_SPECTRUM_FILE), \n",
    "                                          delimiter='\\t', unpack=True)\n",
    "    \n",
    "    # Plot DS-200ty data\n",
    "    plt.loglog(ds200ty_mass, ds200ty_xsec, '-', color='red', linewidth=2.5, \n",
    "             label='DarkSide-20k (200 ton-year)')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DarkSide-200ty full spectrum: {e}\")\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlabel('WIMP Mass [GeV/c²]', fontsize=12)\n",
    "plt.ylabel('WIMP-nucleon σ$_{SI}$ [cm²]', fontsize=12)\n",
    "plt.title('Exclusion 90% C.L.', fontsize=14)\n",
    "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Set axis limitsm\n",
    "plt.xlim(1, 100000)  \n",
    "plt.ylim(1e-48, 1e-39) \n",
    "\n",
    "# Save plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_FOLDER, \"full_spectra_comparison.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e0cef-47dc-48ea-b0a0-6f8b6c440cc5",
   "metadata": {},
   "source": [
    "We will test a few couplings of the mediator to quarks (gq), leptons (gl) and dark matter (test_gdm), for the static version of the plots. The choice of these couplings does not change direct detection results, but they change the sensitivity of the collider results as they influence both production and decay of the mediator in a collider.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c845c13a-4946-47f2-90e6-c4e4a3989b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "gq = 0.25\n",
    "test_gdm = [1.0,0.2,0.1,0.05]\n",
    "gl = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd3f811-4e48-4ed8-bc3c-6843bfdd0549",
   "metadata": {},
   "source": [
    "These two functions are used to convert benchmark points that are constrained in collider space, identified by the couplings, the mediator mass and the DM mass, into benchmark points in the direct detection space of the nucleon-DM spin-dependent and spin-independent cross-section (equation 4.10 and 4.3 of [2]). \n",
    "Note: these conversion formulas do not include effects due to the difference in energy scales of the two experiments [3], but they do not change the picture for the purpose of these plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d042e2e-34ae-4947-a40b-0b09c47f00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eqn 4.10 https://arxiv.org/pdf/1603.04156.pdf#page12\n",
    "def calculate_sd(gq, gdm, gl, mMed, mdm) :\n",
    "\n",
    "    mn = 0.939 # GeV\n",
    "    val = 2.4e-42 * (gq*gdm/0.25)**2 * (1000./mMed)**4 * (mn*mdm/(mn+mdm))**2\n",
    "    return val\n",
    "\n",
    "# eqn 4.3: https://arxiv.org/pdf/1603.04156.pdf#page12\n",
    "def calculate_si(gq, gdm, gl, mMed, mdm) :\n",
    "\n",
    "    mn = 0.939 # GeV\n",
    "    val = 6.9e-41 * (gq*gdm/0.25)**2 * (1000./mMed)**4 * (mn*mdm/(mn+mdm))**2\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449f390-f8e9-4bb5-b23c-11316029dd1b",
   "metadata": {},
   "source": [
    "Some more helper functions (TODO: move outside this notebook at some point...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d24dc58-db07-4c51-a445-a47be8d73d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_vertical(x1,y1,x2,y2,n) :\n",
    "    ov = sorted([[y1,x1],[y2,x2]])\n",
    "    new_ys = np.linspace(ov[0][0], ov[1][0], num=n)\n",
    "    new_xs = np.interp(new_ys,[ov[0][0],ov[1][0]],[ov[0][1],ov[1][1]])\n",
    "    vertices = list(zip(new_xs,new_ys))\n",
    "    return vertices if y1 < y2 else list(reversed(vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2058db-e65b-400b-beec-2cdc6ee1a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    a, b = it.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507b153-fc5b-4b88-a8b9-772dd6f67b48",
   "metadata": {},
   "source": [
    "Here we pick up the different constraints in terms of direct detection DM-nucleon interactions, spin-dependent for proton and neutron separately and spin-independent, and have a helper function that associates legends to curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c00189ae-edc9-42ef-90f0-41becedc3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_proton = collect_dd.get_sd_proton()\n",
    "sd_neutron = collect_dd.get_sd_neutron()\n",
    "spin_independent = collect_dd.get_spin_independent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41556da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spin_independent.update({'Darkside' : [np.array(ds200ty_mass),np.array(ds200ty_xsec)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98e43118-9a91-4192-8904-fca165f8c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect direct detection contours for comparison plots.\n",
    "def get_dd_lines(lineinfo) :\n",
    "    legend_lines = list(lineinfo.keys())\n",
    "    dd_lines = []\n",
    "    for name in legend_lines :\n",
    "        dd_lines.append(lineinfo[name])\n",
    "    return legend_lines, dd_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b47e8a-0be2-4814-8331-323d524bdf07",
   "metadata": {},
   "source": [
    "This function takes care of the plotting given inputs in terms of collider name, kind of model (vector or axial vector mediator), contour lines, legend lines, and what couplings are fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f1b8bec-b4c5-4070-8603-6386b93e3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(collider, model, contours, legend_lines, fix_couplings, extra_tag = \"\") :\n",
    "    xlow = 1\n",
    "    xhigh = 2000 if 'hl-lhc' in collider else 4000\n",
    "    if 'vector' in model : ylow = 1e-48 if 'hl-lhc' in collider else 1e-50\n",
    "    else : ylow = 1e-46 if 'hl-lhc' in collider else 1e-50\n",
    "    yhigh = 1e-37 if 'hl-lhc' in collider else 1e-42    \n",
    "    usepath = \"plots/directdetection/\"+collider\n",
    "    formatters = {\"gq\" : \"q\", \"gdm\" : \"\\chi\", \"gl\" : \"l\"}\n",
    "    treat_as_scaling = False\n",
    "    # At least 2 fixed couplings.\n",
    "    if len(fix_couplings.keys()) > 2 :\n",
    "        label_line =  \"{0}\\n{7}, g$_{5}$={2}\\ng$_{4}$={1}, g$_{6}$={3}\".format((\"Axial-vector\" if 'axial' in model else \"Vector\"),fix_couplings[\"gq\"],fix_couplings[\"gdm\"],fix_couplings[\"gl\"],\"q\",\"\\chi\",\"l\",collider.upper())\n",
    "        tag_line = model+\"_gq{0}_gdm{1}_gl{2}\".format(fix_couplings[\"gq\"],fix_couplings[\"gdm\"],fix_couplings[\"gl\"])\n",
    "    else :\n",
    "        treat_as_scaling = True\n",
    "        usecouplings = list(fix_couplings.keys())\n",
    "        useformats = []\n",
    "        vals = []\n",
    "        for coupling in usecouplings :\n",
    "            useformats.append(formatters[coupling])\n",
    "            vals.append(fix_couplings[coupling])\n",
    "        label_line = \"{0}, {5}\\ng$_{3}$={1}, g$_{4}$={2}\".format((\"Axial-vector\" if 'axial' in model else \"Vector\"),vals[0],vals[1],useformats[0],useformats[1],collider.upper())\n",
    "        tag_line = model+\"_{0}{1}_{2}{3}\".format(usecouplings[0],vals[0],usecouplings[1],vals[1])\n",
    "    if extra_tag : tag_line = tag_line + \"_\" + extra_tag\n",
    "    # And draw. First, version without DD experiment lines\n",
    "    # Then draw the plots with DD lines on\n",
    "    if 'vector' in model :\n",
    "        # If doing fcc-hh, remove MIGD line which is too high up to be seen.\n",
    "        formatted_lines = get_dd_lines(spin_independent)\n",
    "        ddcurves = []\n",
    "        ddnames = []\n",
    "        for name, line in zip(formatted_lines[0],formatted_lines[1]) :\n",
    "            if not ('fcc' in collider and 'MIGD' in name) :\n",
    "                ddcurves.append(line)\n",
    "                ddnames.append(name)\n",
    "        use_ylabel = \"$\\sigma_{SI}$ ($\\chi$-nucleon) [cm$^2$]\"\n",
    "        drawDDPlot(contours,legend_lines, this_tag = tag_line, plot_path = usepath, addText = label_line, ylabel=use_ylabel, is_scaling=treat_as_scaling, transluscent=treat_as_scaling, xhigh=xhigh, ylow=ylow, yhigh=yhigh)\n",
    "        drawDDPlot(contours,legend_lines, this_tag = tag_line+\"_withDD\", plot_path = usepath, addText = label_line, ylabel=use_ylabel, is_scaling=treat_as_scaling, transluscent=treat_as_scaling, xhigh=xhigh, ylow=ylow, yhigh=yhigh, dd_curves = ddcurves, dd_legendlines = ddnames)\n",
    "    else :\n",
    "        use_ylabel = \"$\\sigma_{SD}$ ($\\chi$-nucleon) [cm$^2$]\"\n",
    "        drawDDPlot(contours,legend_lines, this_tag = tag_line, plot_path = usepath, addText = label_line, ylabel=use_ylabel, is_scaling=treat_as_scaling, transluscent=treat_as_scaling, xhigh=xhigh, ylow=ylow, yhigh=yhigh)\n",
    "        formatted_lines_p = get_dd_lines(sd_proton)\n",
    "        use_ylabel = \"$\\sigma_{SD}$ ($\\chi$-proton) [cm$^2$]\"\n",
    "        drawDDPlot(contours,legend_lines, this_tag = tag_line+\"_withDD_proton\", plot_path = usepath, addText = label_line, ylabel=use_ylabel, is_scaling=treat_as_scaling, transluscent=treat_as_scaling, xhigh=xhigh, ylow=ylow, yhigh=yhigh, dd_curves = formatted_lines_p[1], dd_legendlines = formatted_lines_p[0])  \n",
    "        formatted_lines_n = get_dd_lines(sd_neutron)\n",
    "        use_ylabel = \"$\\sigma_{SD}$ ($\\chi$-neutron) [cm$^2$]\"\n",
    "        drawDDPlot(contours,legend_lines, this_tag = tag_line+\"_withDD_neutron\", plot_path = usepath, addText = label_line, ylabel=use_ylabel, is_scaling=treat_as_scaling, transluscent=treat_as_scaling, xhigh=xhigh, ylow=ylow, yhigh=yhigh, dd_curves = formatted_lines_n[1], dd_legendlines = formatted_lines_n[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7b6dd-3b7b-4c6d-9b20-4a434482e52b",
   "metadata": {},
   "source": [
    "Here we load all the files including polygons for the HL-LHC vector mediated DM benchmark models, and make different grids of plots with different options using python dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bf0091-3dac-4c9d-8948-1af8c937ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle files with polygons\n",
    "# Limits with fixed couplings\n",
    "for collider in ['hl-lhc', 'fcc-hh'] :\n",
    "    with open('{0}_exclusion_contours_{1}.pkl'.format('vector',collider), \"rb\") as poly_file:\n",
    "        loaded_polygons = pickle.load(poly_file)\n",
    "        \n",
    "        # Grid of plots:\n",
    "        exclusions_dd = {'dijet' : {}}\n",
    "        exclusions_separate_dd = {'dijet' : {}}\n",
    "\n",
    "        # And now third set of plots with gq and gl fixed:\n",
    "        contours_list_couplingscan = []\n",
    "        legend_lines_couplingscan = []\n",
    "        for gdm in test_gdm :\n",
    "            contours_list = []\n",
    "            # e.g. no coupling to leptons, skip:\n",
    "            if (gq, gdm, gl) not in exclusions_dd['dijet'].keys() :\n",
    "                continue                            \n",
    "            exclusions = exclusions_dd['dijet'][(gq, gdm, gl)]\n",
    "            contours_list+=exclusions\n",
    "            if all(not i for i in contours_list) : continue\n",
    "            full_polygons = merge_exclusions(contours_list)\n",
    "            contours_list_couplingscan.append(full_polygons)\n",
    "            legend_lines_couplingscan.append(\"g$_{0}$={1}\".format(\"\\chi\",gdm))\n",
    "        make_plots(collider, 'vector', contours_list_couplingscan, legend_lines_couplingscan, {\"gq\" : gq, \"gl\" : gl})\n",
    "        # A version overlaying all monojet and overlaying all dijet, but not combining\n",
    "        sub_contours_list = []\n",
    "        sub_legends_list = []\n",
    "        for gdm in test_gdm :\n",
    "            if (gq, gdm, gl) not in exclusions_separate_dd['dijet'].keys() : continue\n",
    "            sub_contours_list.append(exclusions_separate_dd['dijet'][(gq, gdm, gl)])\n",
    "            sub_legends_list.append(\"g$_{0}$={1}\".format(\"\\chi\",gdm))                   \n",
    "        make_plots(collider, 'vector', sub_contours_list,sub_legends_list, {\"gq\" : gq, \"gl\" : gl}, extra_tag = 'dijet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80e21d-41b3-4f51-a08a-8382cad4de68",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "[1] A. Boveia et al., Dark Matter Benchmark Models for Early LHC Run-2 Searches: Report of the ATLAS/CMS Dark Matter Forum, https://doi.org/10.1016/j.dark.2019.100371 \n",
    "\n",
    "[2] https://arxiv.org/pdf/1603.04156#page12\n",
    "\n",
    "[3] https://arxiv.org/abs/1411.3342\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
